{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fed47c4e-d9b0-4e57-bbd0-5d4e7423ab95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (3.7.4)\n",
      "Requirement already satisfied: textblob in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (0.18.0.post0)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (8.2.3)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (0.9.4)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.10.12)\n",
      "Requirement already satisfied: jinja2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (68.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\administrator.dai-pc2\\appdata\\roaming\\python\\python311\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk spacy textblob -U\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d006b63-4714-448f-bb77-c10107133025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25784d3-6d00-474e-87bd-5d931176e5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package indian to C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package indian is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\Administrator.DAI-\n",
      "[nltk_data]     PC2\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')#tokenization\n",
    "nltk.download(\"stopwords\")#stopwords removel\n",
    "nltk.download(\"averaged_perceptron_tagger\")#POS tagging\n",
    "nltk.download(\"wordnet\")#wordnet database and lemmatization\n",
    "nltk.download(\"omw-1.4\")#stemming\n",
    "nltk.download(\"indian\")#indian language POS tagging\n",
    "nltk.download(\"maxent_ne_chunker\")#chunking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8da1fbb-99ee-4af6-852c-91dab8c64fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent='They told that their ages are 25 27 and 31 respectively.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7dad955-30d6-4bc9-ac3a-adfbc0f3fb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the average of ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9740cbe-a435-4dee-8a03-346788696f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "ages=[]\n",
    "for word in sent.split():\n",
    "    if word.isdigit():\n",
    "        ages.append(int(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8da1fc77-fd59-49f6-b19b-3951af0bd58c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ages)/len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d3345e-f7f7-4f2e-887b-80cc6e12aff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ages=[int(word) for word in sent.split() if word.isdigit() ]\n",
    "sum(ages)/len(ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94ba2767-58ec-4841-ad39-b84db5b786f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a17e122-94ba-4074-ae8d-d5d5b5a2cfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27.666666666666668"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([int(word) for word in sent.split() if word.isdigit() ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33831edc-246a-4cba-9ad5-1e94e6bb05e3",
   "metadata": {},
   "source": [
    "##Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "613afc34-e635-4b4d-b129-03e648b56751",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent=\"Hello friends! How are you? Welcome to python Programming.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bacfc955-4fdb-4bab-beee-ba89df15fa27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3252316-a13e-4b5e-91b8-9a6f333a8542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello friends!', 'How are you?', 'Welcome to python Programming.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "178fed0e-74a2-4e9e-a856-2273a9965801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'friends',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'python',\n",
       " 'Programming',\n",
       " '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word=word_tokenize(sent)\n",
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73c56f76-bdd1-446e-9273-b6fa1c0f82a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find percentage of punctuation symbols present int it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc64e74-37e1-447d-a24e-a7f514a4ebb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_count=len([word for word in word_tokenize(sent) if not word.isalnum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2830062-4f9e-4a0c-a111-1e2fc17f5df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punct_count/len(word_tokenize(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d3af0ff-7ae7-42e5-a5e0-909d70ec86b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5edae168-77ae-4f12-952f-193e362d6dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "114"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('r')#ASCII value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4ed7d356-ed95-463f-b15d-ece46745084f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c6e52345-8cbe-4f57-bcc6-3f2d869e8053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.getsizeof('=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bd6a743-fee2-48c8-a0b8-7df17ca76961",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function getsizeof in module sys:\n",
      "\n",
      "getsizeof(...)\n",
      "    getsizeof(object [, default]) -> int\n",
      "    \n",
      "    Return the size of object in bytes.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(sys.getsizeof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04d95ccf-950e-4a26-976e-4328aa492e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char='dsgdbvcbfgfg'\n",
    "sys.getsizeof(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e7f56f96-8801-43c0-b146-3c9a78f99fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(67)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8441435f-2ff1-45b5-93e0-fe36912b8894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ࠓ'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(2067)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f4fe0840-571a-4ea2-b0cc-81f409de941e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "व\n"
     ]
    }
   ],
   "source": [
    "char='\\u0935'\n",
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0a18ce59-ea59-4115-ac54-e3d6da1ef75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "वी\n"
     ]
    }
   ],
   "source": [
    "char='\\u0935\\u0940'\n",
    "print(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f6d595d-7b5f-4a8a-b8fc-7553ab5b2ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2357"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord('व')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dfbc0a68-ae70-4367-bb56-e3251c245418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'श'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(2358)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e81be58-f332-4869-9c7b-f2a4f12a8678",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'व'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chr(0x935)#hex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64f08cf7-4e12-48c3-8bfa-a26ae476fcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof('व')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b540bae-4bdd-49c7-a16f-165266f348cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.google.com/intl/sa/inputtools/try/\n",
    "name='ऋतूजा'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d2744c0-a2cf-4980-bdeb-13e1cb53d961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.startswith('ऋ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d9d5f2c7-6f59-45f6-819a-598f869035b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'रुतूजा'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.replace('ऋ','रु')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbb89893-f322-4dd2-961e-ebeb6938181a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name.find('जा')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90e3eabc-bb55-46c6-a334-a4865e44dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "प्रणव\n",
      "प्रातिक्षा\n"
     ]
    }
   ],
   "source": [
    "names=['ऋतुजा','प्रणव','प्रातिक्षा','ओम ' ]\n",
    "for name in names:\n",
    "    if name.startswith('प्र'):\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1d612d3e-d81f-46ee-931f-0ae8a920d3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtext = 'राजगड हा भारताच्या महाराष्ट्र राज्यातील एक किल्ला आहे. राजगड Archived 2020-08-05 at the Wayback Machine. किल्ल्यावर छत्रपती शिवाजी महाराज यांच्या स्वराज्याची पहिली राजधानी होती. पुणे शहराच्या नैऋत्येला'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "904b92d3-6fd3-4509-b9ea-fdcf697ddb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['राजगड',\n",
       " 'हा',\n",
       " 'भारताच्या',\n",
       " 'महाराष्ट्र',\n",
       " 'राज्यातील',\n",
       " 'एक',\n",
       " 'किल्ला',\n",
       " 'आहे.',\n",
       " 'राजगड',\n",
       " 'Archived',\n",
       " '2020-08-05',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Wayback',\n",
       " 'Machine.',\n",
       " 'किल्ल्यावर',\n",
       " 'छत्रपती',\n",
       " 'शिवाजी',\n",
       " 'महाराज',\n",
       " 'यांच्या',\n",
       " 'स्वराज्याची',\n",
       " 'पहिली',\n",
       " 'राजधानी',\n",
       " 'होती.',\n",
       " 'पुणे',\n",
       " 'शहराच्या',\n",
       " 'नैऋत्येला']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtext.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc278041-49a4-4010-b64b-379cafcc0b15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['राजगड',\n",
       " 'हा',\n",
       " 'भारताच्या',\n",
       " 'महाराष्ट्र',\n",
       " 'राज्यातील',\n",
       " 'एक',\n",
       " 'किल्ला',\n",
       " 'आहे',\n",
       " '.',\n",
       " 'राजगड',\n",
       " 'Archived',\n",
       " '2020-08-05',\n",
       " 'at',\n",
       " 'the',\n",
       " 'Wayback',\n",
       " 'Machine',\n",
       " '.',\n",
       " 'किल्ल्यावर',\n",
       " 'छत्रपती',\n",
       " 'शिवाजी',\n",
       " 'महाराज',\n",
       " 'यांच्या',\n",
       " 'स्वराज्याची',\n",
       " 'पहिली',\n",
       " 'राजधानी',\n",
       " 'होती',\n",
       " '.',\n",
       " 'पुणे',\n",
       " 'शहराच्या',\n",
       " 'नैऋत्येला']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(mtext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed7d025-7d7d-47ca-8e78-fa038475ee14",
   "metadata": {},
   "source": [
    "## Space Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "01304780-f119-4a42-b420-bb1e1080961a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello FriendsðŸ˜€!\\tHow are youðŸ«\\xa0?\\nWelcomeðŸ«° to the worldðŸŒŽ of\\tPythonâ™” ProgrammingðŸ˜·.'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path=r\"mydata.txt\"\n",
    "open(path).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7a3e2776-9a84-4c92-bd6a-107e390031cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(path).readable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0f03ff32-d213-4df7-9d05-cc5932bf3292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello FriendsðŸ˜€!\\tHow are youðŸ«\\xa0?\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(path).readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "717c8247-7efa-4eef-bbe7-e44c081768de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello FriendsðŸ˜€!\\tHow are youðŸ«\\xa0?\\n',\n",
       " 'WelcomeðŸ«° to the worldðŸŒŽ of\\tPythonâ™” ProgrammingðŸ˜·.']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open(path).readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52c7d40e-0acf-4200-bb1e-d79f2931cc34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello FriendsðŸ˜€!\\tHow are youðŸ«\\xa0?\\nWelcomeðŸ«° to the worldðŸŒŽ of\\tPythonâ™” ProgrammingðŸ˜·.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f=open('mydata.txt')\n",
    "data = f.read()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55aae687-689e-410e-8c50-a3f4ef7d892e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'FriendsðŸ˜€!\\tHow',\n",
       " 'are',\n",
       " 'youðŸ«\\xa0?\\nWelcomeðŸ«°',\n",
       " 'to',\n",
       " 'the',\n",
       " 'worldðŸŒŽ',\n",
       " 'of\\tPythonâ™”',\n",
       " 'ProgrammingðŸ˜·.']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the class\n",
    "from nltk.tokenize import SpaceTokenizer\n",
    "#create the object\n",
    "tk = SpaceTokenizer()\n",
    "#tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488c87ba-14e8-434a-8b64-8aba41d84052",
   "metadata": {},
   "source": [
    "## Tab tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2ea0ae4-58ea-4b39-9756-64b3edc7ddea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello FriendsðŸ˜€!\tHow are youðŸ« ?\n",
      "WelcomeðŸ«° to the worldðŸŒŽ of\tPythonâ™” ProgrammingðŸ˜·.\n"
     ]
    }
   ],
   "source": [
    "f=open('mydata.txt')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "baa408e3-1968-4ab8-b043-d9295589e088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello FriendsðŸ˜€!',\n",
       " 'How are youðŸ«\\xa0?\\nWelcomeðŸ«° to the worldðŸŒŽ of',\n",
       " 'Pythonâ™” ProgrammingðŸ˜·.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the class\n",
    "from nltk.tokenize import TabTokenizer\n",
    "#create the object\n",
    "tk = TabTokenizer()\n",
    "#tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902d7206-38a9-4363-960e-c87e3325112b",
   "metadata": {},
   "source": [
    "## Line Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "37b49506-8815-4e0d-9cc4-075f1143bce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello FriendsðŸ˜€!\\tHow are youðŸ«\\xa0?',\n",
       " 'WelcomeðŸ«° to the worldðŸŒŽ of\\tPythonâ™” ProgrammingðŸ˜·.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the class\n",
    "from nltk.tokenize import LineTokenizer\n",
    "#create the object\n",
    "tk = LineTokenizer()\n",
    "#tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa0a208-5e1d-4059-b1aa-d37655e92ccc",
   "metadata": {},
   "source": [
    "## Whitespace Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "11ef34fc-e72c-4eff-9abf-d04bed28d13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'FriendsðŸ˜€!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'youðŸ«',\n",
       " '?',\n",
       " 'WelcomeðŸ«°',\n",
       " 'to',\n",
       " 'the',\n",
       " 'worldðŸŒŽ',\n",
       " 'of',\n",
       " 'Pythonâ™”',\n",
       " 'ProgrammingðŸ˜·.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the class\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "#create the object\n",
    "tk = WhitespaceTokenizer()\n",
    "#tokenize the data\n",
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c63070a-b502-4d5e-bf90-d47e18dd537b",
   "metadata": {},
   "source": [
    "## MultiWordExpression [MWE] Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3b421bc-682b-4e26-935b-15b17ae51768",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = 'The Van Rossum is python creator, visiting Pune this week. The development community is very eager to meet Van Rossum.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "85664dc6-4895-41f0-8f3c-edc8dae6cd1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Van Rossum is python creator, visiting Pune this week. The development community is very eager to meet Van Rossum.\n"
     ]
    }
   ],
   "source": [
    "print(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "37e98269-dcbe-456c-a98e-59e7d5e5dd37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van',\n",
       " 'Rossum',\n",
       " 'is',\n",
       " 'python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visiting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'development',\n",
       " 'community',\n",
       " 'is',\n",
       " 'very',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van',\n",
       " 'Rossum',\n",
       " '.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sent1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5739213d-03ae-47c3-8687-bd0adb5570e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'Van Rossum',\n",
       " 'is',\n",
       " 'python',\n",
       " 'creator',\n",
       " ',',\n",
       " 'visiting',\n",
       " 'Pune',\n",
       " 'this',\n",
       " 'week',\n",
       " '.',\n",
       " 'The',\n",
       " 'development',\n",
       " 'community',\n",
       " 'is',\n",
       " 'very',\n",
       " 'eager',\n",
       " 'to',\n",
       " 'meet',\n",
       " 'Van Rossum',\n",
       " '.']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the class\n",
    "from nltk.tokenize import MWETokenizer\n",
    "#create the object\n",
    "tk = MWETokenizer(separator=' ')\n",
    "#add multi word expression\n",
    "tk.add_mwe(('Van','Rossum'))\n",
    "#tokenize the data\n",
    "tk.tokenize(word_tokenize(sent1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7079564-b787-4674-9524-8daafb307781",
   "metadata": {},
   "source": [
    "## Tweet Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "31f719ac-a93c-45a1-8ff8-c4ac1a658c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Hello Friends :) ! How are you :( ? Welcome to the world of Python Programming. :D\n"
     ]
    }
   ],
   "source": [
    "sent=\"'Hello Friends :) ! How are you :( ? Welcome to the world of Python Programming. :D\"\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "bb0db6b0-d1ee-4eaa-9803-8d6a0d72d506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"'\",\n",
       " 'Hello',\n",
       " 'Friends',\n",
       " ':)',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " ':(',\n",
       " '?',\n",
       " 'Welcome',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " 'of',\n",
       " 'Python',\n",
       " 'Programming',\n",
       " '.',\n",
       " ':D']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import the class\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "#create the object\n",
    "tk = TweetTokenizer()\n",
    "#tokenize the data\n",
    "tk.tokenize(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1b957248-c805-4a07-b4b0-63cb6479aad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Friends😀!\tHow are you🫠?\n",
      "Welcome🫰 to the world🌎 of\tPython♔ Programming😷.\n"
     ]
    }
   ],
   "source": [
    "f=open('mydata.txt', encoding='utf-8')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1651a4af-6275-4b4c-8a43-5bfa675a998d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends😀',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you🫠',\n",
       " '?',\n",
       " 'Welcome🫰',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world🌎',\n",
       " 'of',\n",
       " 'Python♔',\n",
       " 'Programming😷',\n",
       " '.']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ccf4024-b1e6-485d-b8e6-fb6f4cf1a605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Friends',\n",
       " '😀',\n",
       " '!',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '🫠',\n",
       " '?',\n",
       " 'Welcome',\n",
       " '🫰',\n",
       " 'to',\n",
       " 'the',\n",
       " 'world',\n",
       " '🌎',\n",
       " 'of',\n",
       " 'Python',\n",
       " '♔',\n",
       " 'Programming',\n",
       " '😷',\n",
       " '.']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tk.tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e01ed7-249a-4971-b816-c9572176184a",
   "metadata": {},
   "source": [
    "## Custom Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e9a89351-b5dd-4a59-82d0-3d15d8dca1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: \n",
      "This\n",
      "is\n",
      "some\n",
      "text\n",
      "punctuation\n",
      ">\n",
      "Let's\n",
      "tokenize\n",
      "it\n",
      "Is\n",
      "it\n",
      "ok\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def custom_tokenizer(text):\n",
    "    return re.split(r'[.,;?!\\s]+',text)\n",
    "text = \"This is some text punctuation > Let's tokenize it. Is it ok?\"\n",
    "\n",
    "tokens = custom_tokenizer(text)\n",
    "\n",
    "print('Tokens: ')\n",
    "for token in tokens:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3fe0c5f5-f6a0-48cf-80aa-35e5c2dc0407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roll\tname\tclass\tmarks\tage\n",
      "1\tanil\tTE\t56.77\t22\n",
      "2\tamit\tTE\t59.77\t21\n",
      "3\taniket\tBE\t76.88\t19\n",
      "4\tajinkya\tTE\t69.66\t20\n",
      "5\tasha\tTE\t63.28\t20\n",
      "6\tayesha\tBE\t49.55\t20\n",
      "7\tamar\tBE\t65.34\t19\n",
      "8\tamita\tBE\t68.33\t23\n",
      "9\tamol\tTE\t56.75\t20\n",
      "10\tanmol\tBE\t78.66\t21\n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('student3.tsv')\n",
    "data = f.read()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "814e4480-ce05-440b-82e3-ad1c8fe41efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split('\\n')\n",
    "lst=[]\n",
    "for x in data:\n",
    "    inner_lst=[]\n",
    "    for y in x.split('\\t'):\n",
    "        if(y.isdigit()):\n",
    "            inner_lst.append(int(y))\n",
    "        elif y.find('.')>0:\n",
    "            inner_lst.append(float(y))\n",
    "        else:\n",
    "            inner_lst.append(y)\n",
    "    lst.append(inner_lst)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f7b16c-913c-40b4-9fc0-e5127e9ecc8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bf5d85-3a3f-44ec-9e35-4d45a99cb25e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
